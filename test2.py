import pickle
import json
from pprint import pprint
import pandas as pd
import numpy as np

def show_actual_training_content(obj, max_samples=10, max_text_length=200):
    """ì‹¤ì œ í•™ìŠµ ë°ì´í„° ë‚´ìš©ì„ ìì„¸íˆ í‘œì‹œ"""
    
    print("\n" + "="*80)
    print("ğŸ“– ACTUAL TRAINING DATA CONTENT")
    print("="*80)
    
    def display_data_samples(data, label, max_samples=max_samples):
        print(f"\nğŸ¯ {label}:")
        print("-" * 50)
        
        if isinstance(data, np.ndarray):
            print(f"ğŸ“ Shape: {data.shape}")
            print(f"ğŸ”¢ Data type: {data.dtype}")
            
            # 1ì°¨ì› ë°°ì—´ (ë¼ë²¨ ë“±)
            if len(data.shape) == 1:
                print(f"ğŸ“Š Sample values ({min(max_samples, len(data))} out of {len(data)}):")
                for i in range(min(max_samples, len(data))):
                    print(f"   [{i:3d}]: {data[i]}")
                    
            # 2ì°¨ì› ë°°ì—´ (íŠ¹ì„± ë²¡í„° ë“±)
            elif len(data.shape) == 2:
                print(f"ğŸ“Š Sample rows ({min(max_samples, len(data))} out of {len(data)}):")
                for i in range(min(max_samples, len(data))):
                    row_str = str(data[i][:10].tolist())  # ì²˜ìŒ 10ê°œ íŠ¹ì„±ë§Œ
                    if data.shape[1] > 10:
                        row_str = row_str[:-1] + ", ...]"
                    print(f"   Row [{i:3d}]: {row_str}")
                    
        elif isinstance(data, (list, tuple)):
            print(f"ğŸ“ Length: {len(data)}")
            print(f"ğŸ“Š Sample items ({min(max_samples, len(data))} out of {len(data)}):")
            
            for i in range(min(max_samples, len(data))):
                item = data[i]
                if isinstance(item, str):
                    # í…ìŠ¤íŠ¸ ë°ì´í„°ì¸ ê²½ìš° - ì´ë©”ì¼ ë‚´ìš© ë“±
                    display_text = item[:max_text_length]
                    if len(item) > max_text_length:
                        display_text += "..."
                    print(f"   [{i:3d}]: \"{display_text}\"")
                else:
                    print(f"   [{i:3d}]: {item}")
                    
        elif isinstance(data, pd.DataFrame):
            print(f"ğŸ“ Shape: {data.shape}")
            print(f"ğŸ“‹ Columns: {data.columns.tolist()}")
            print(f"ğŸ“Š Sample data:")
            print(data.head(max_samples).to_string(max_cols=6, max_colwidth=50))
    
    # ë”•ì…”ë„ˆë¦¬ì—ì„œ í•™ìŠµ ë°ì´í„° ì°¾ê¸°
    if isinstance(obj, dict):
        # ì¼ë°˜ì ì¸ í•™ìŠµ ë°ì´í„° í‚¤ë“¤
        data_keys = ['X_train', 'y_train', 'X_test', 'y_test', 'X', 'y', 
                    'training_data', 'train_data', 'emails', 'texts', 'labels',
                    'features', 'targets', 'data', 'dataset']
        
        found_data = False
        for key in obj.keys():
            # í‚¤ ì´ë¦„ìœ¼ë¡œ í•™ìŠµ ë°ì´í„° ì°¾ê¸°
            if any(data_key.lower() in key.lower() for data_key in data_keys):
                display_data_samples(obj[key], f"Data from key '{key}'")
                found_data = True
        
        # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ëª¨ë“  ë°°ì—´/ë¦¬ìŠ¤íŠ¸ íƒ€ì… í‘œì‹œ
        if not found_data:
            print("\nâš ï¸  No obvious training data keys found. Showing all array/list data:")
            for key, value in obj.items():
                if isinstance(value, (np.ndarray, list, tuple, pd.DataFrame)):
                    display_data_samples(value, f"Data from key '{key}'")
    
    # ë¦¬ìŠ¤íŠ¸ë‚˜ ë°°ì—´ì¸ ê²½ìš°
    elif isinstance(obj, (list, tuple, np.ndarray)):
        display_data_samples(obj, "Root data structure")

def extract_text_content(obj, max_samples=15):
    """í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ì¶”ì¶œí•˜ì—¬ í‘œì‹œ (ì´ë©”ì¼, í…ìŠ¤íŠ¸ ë“±)"""
    
    print("\n" + "="*80)
    print("ğŸ“ TEXT CONTENT EXTRACTION")
    print("="*80)
    
    def find_and_display_text(data, path=""):
        text_found = False
        
        if isinstance(data, dict):
            for key, value in data.items():
                current_path = f"{path}.{key}" if path else key
                if find_and_display_text(value, current_path):
                    text_found = True
                    
        elif isinstance(data, (list, tuple)):
            if len(data) > 0 and isinstance(data[0], str):
                print(f"\nğŸ”¤ Text data found at: {path}")
                print(f"ğŸ“ Count: {len(data)} items")
                print("ğŸ“„ Sample texts:")
                print("-" * 60)
                
                for i, text in enumerate(data[:max_samples]):
                    # ì´ë©”ì¼ í—¤ë”ë‚˜ HTML íƒœê·¸ ê°„ë‹¨íˆ ì •ë¦¬
                    clean_text = str(text).replace('\n', ' ').replace('\r', '')
                    if len(clean_text) > 300:
                        clean_text = clean_text[:300] + "..."
                        
                    print(f"\n[{i+1:2d}] {clean_text}")
                    
                if len(data) > max_samples:
                    print(f"\n... and {len(data) - max_samples} more text items")
                text_found = True
                
        elif isinstance(data, np.ndarray) and data.dtype.kind in ['U', 'S', 'O']:  # ë¬¸ìì—´ íƒ€ì…
            print(f"\nğŸ”¤ Text array found at: {path}")
            print(f"ğŸ“ Shape: {data.shape}")
            print("ğŸ“„ Sample texts:")
            print("-" * 60)
            
            for i in range(min(max_samples, len(data))):
                text = str(data[i])
                if len(text) > 300:
                    text = text[:300] + "..."
                print(f"\n[{i+1:2d}] {text}")
                
            text_found = True
            
        return text_found
    
    if not find_and_display_text(obj):
        print("âŒ No text content found in the data structure.")

def comprehensive_data_viewer(file_path, max_samples=10, show_text=True):
    """í¬ê´„ì ì¸ ë°ì´í„° ë‚´ìš© ë·°ì–´"""
    
    print("="*80)
    print(f"ğŸ” COMPREHENSIVE DATA CONTENT VIEWER")
    print(f"ğŸ“ File: {file_path}")
    print("="*80)
    
    try:
        with open(file_path, 'rb') as f:
            loaded_object = pickle.load(f)
        
        print(f"âœ… File loaded successfully!")
        print(f"ğŸ“Š Root type: {type(loaded_object).__name__}")
        
        # 1. ê¸°ë³¸ êµ¬ì¡° ì •ë³´
        if isinstance(loaded_object, dict):
            print(f"ğŸ“š Dictionary with {len(loaded_object)} keys:")
            for key, value in loaded_object.items():
                print(f"   ğŸ”‘ '{key}': {type(value).__name__}", end="")
                if hasattr(value, 'shape'):
                    print(f" - Shape: {value.shape}")
                elif hasattr(value, '__len__'):
                    try:
                        print(f" - Length: {len(value)}")
                    except:
                        print("")
                else:
                    print("")
        
        # 2. ì‹¤ì œ í•™ìŠµ ë°ì´í„° ë‚´ìš© í‘œì‹œ
        show_actual_training_content(loaded_object, max_samples)
        
        # 3. í…ìŠ¤íŠ¸ ë‚´ìš© ì¶”ì¶œ (ì´ë©”ì¼ ë“±)
        if show_text:
            extract_text_content(loaded_object, max_samples)
        
        # 4. í†µê³„ ì •ë³´
        print("\n" + "="*80)
        print("ğŸ“ˆ DATA STATISTICS")
        print("="*80)
        
        def show_statistics(data, label):
            print(f"\nğŸ“Š {label}:")
            if isinstance(data, np.ndarray):
                if data.dtype.kind in ['i', 'f']:  # ìˆ«ì ë°ì´í„°
                    print(f"   Min: {np.min(data):.4f}")
                    print(f"   Max: {np.max(data):.4f}")
                    print(f"   Mean: {np.mean(data):.4f}")
                    print(f"   Std: {np.std(data):.4f}")
                elif data.dtype.kind in ['U', 'S', 'O']:  # ë¬¸ìì—´ ë°ì´í„°
                    unique_count = len(np.unique(data)) if data.size < 10000 else "Large dataset"
                    print(f"   Unique values: {unique_count}")
                    print(f"   Sample unique values: {np.unique(data)[:5].tolist()}")
        
        if isinstance(loaded_object, dict):
            for key, value in loaded_object.items():
                if isinstance(value, np.ndarray):
                    show_statistics(value, f"'{key}'")
        
        print("\n" + "="*80)
        print("âœ¨ Comprehensive analysis complete!")
        
    except Exception as e:
        print(f"âŒ Error: {str(e)}")
        import traceback
        traceback.print_exc()

# ì‚¬ìš©ë²•
if __name__ == "__main__":
    # íŒŒì¼ ê²½ë¡œë¥¼ ì‹¤ì œ PKL íŒŒì¼ë¡œ ë³€ê²½í•˜ì„¸ìš”
    file_path = 'phishing_knowledge_base.pkl'
    
    print("ğŸ¯ Select viewing option:")
    print("1. Show sample data (10 samples)")
    print("2. Show more data (25 samples)")
    print("3. Show extensive data (50 samples)")
    print("4. Custom sample count")
    
    choice = input("Enter choice (1-4, default=1): ").strip() or "1"
    
    if choice == "1":
        comprehensive_data_viewer(file_path, max_samples=10)
    elif choice == "2":
        comprehensive_data_viewer(file_path, max_samples=25)
    elif choice == "3":
        comprehensive_data_viewer(file_path, max_samples=50)
    elif choice == "4":
        try:
            samples = int(input("Enter number of samples to show: "))
            comprehensive_data_viewer(file_path, max_samples=samples)
        except:
            comprehensive_data_viewer(file_path, max_samples=10)
    else:
        comprehensive_data_viewer(file_path, max_samples=10)